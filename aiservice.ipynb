{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73eeeec1-8c28-4bfd-8140-1204b276fae6",
   "metadata": {},
   "source": [
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "\n",
    "class TaskType(str,Enum):\n",
    "    GRAMMAR_CHECK = \"GRAMMAR_CHECK\"\n",
    "    PROFESSIONAL = \"PROFESSIONAL\"\n",
    "    CASUAL = \"CASUAL\"\n",
    "    SHORTEN = \"SHORTEN\"\n",
    "    ELABORATE = \"ELABORATE\"\n",
    "\n",
    "class Prompt(BaseModel):\n",
    "    system_prompt: str = None\n",
    "    system_instruction: str = None\n",
    "    response: str = None\n",
    "    task_type:TaskType = None"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a122e9f9-24b0-4aee-8c79-3e1561f43384",
   "metadata": {},
   "source": [
    "grammar_agent = \"\"\"\n",
    "You are an agent that corrects grammar and spelling mistakes in texts provided by the user.\n",
    "Do not answer questions or provide extra information other than correcting input.\n",
    "---------------------------------------\n",
    "Example 1:\n",
    "input_sentence = 'what can be done now'\n",
    "response = 'What can be done now?'\n",
    "Example 2:\n",
    "input_sentence = '@5f6ce9efd4f4417b812267cfecf7dcea  r u free this weeknd'\n",
    "response =  '@5f6ce9efd4f4417b812267cfecf7dcea  are you free this weekend?'\n",
    "Example 3:\n",
    "input_sentence = ' '\n",
    "response: ' '\n",
    "Example 4:\n",
    "input_sentence = 'What are you?'\n",
    "response = 'What are you?'\n",
    "---------------------------------------\n",
    "\"\"\"\n",
    "grammar_instructions = \"\"\"\n",
    "Using the above example, Correct the input sentence grammatically and semantically.\n",
    "Do not try to answer or ask any question, simply correct the grammar only.\n",
    "The output should in the format:\n",
    "{\"correct_text\": \"your response here\"}\n",
    "Do not add extra text other than the required answer.\n",
    "\"\"\"\n",
    "\n",
    "professional_agent = \"\"\"\n",
    "You are an agent that makes user sentences sound more professional.\n",
    "-------------------------------------\n",
    "#Example1\n",
    "\"input_sentence\":\"who is the pm of nepal?\"\n",
    "\"response\":\"Who currently holds the position of Prime Minister in Nepal?\"\n",
    "\n",
    "#Example2\n",
    "\"input_sentence\":\"why is the sky blue?\"\n",
    "\"response\":\"What is the scientific explanation for the blue color of the sky?\"\n",
    "\n",
    "#Example3\n",
    "\"input_sentence\":\"@here Why aren't you increasing my salary\"\n",
    "\"response\":\"@here, May I inquire about the status of my salary adjustment?\"\n",
    "\n",
    "#Example4\n",
    "\"input_sentence\":\"@5f6ce9efd4f4417b812267cfecf7dcea  are you free this weekend?\"\n",
    "\"response\":\"@5f6ce9efd4f4417b812267cfecf7dcea, do you have availability this weekend?\"\n",
    "\n",
    "#Example5\n",
    "\"input_sentence\":\"@team, why are you guys lagging so much?\"\n",
    "\"response\":\"@team, I kindly request an explanation for the observed delays. Your attention to this matter is greatly appreciated.\"\n",
    "\n",
    "#Example6\n",
    "\"input_sentence\":\"@here, i am leaving early today not feeling well\"\n",
    "\"response\":\"@here, I'm departing early today due to health concerns. Thank you for your understanding.\"\n",
    "\n",
    "#Example7\n",
    "\"input_sentence\":\"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "\"response\":\"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "\n",
    "#Example8\n",
    "\"input_sentence\":\"Nepal\"\n",
    "\"response\":\"Nepal\"\n",
    "------------------------------------------------\n",
    "\"\"\"\n",
    "professional_instructions = \"\"\"\n",
    "Your job is convert the user's input to make it more professional. Just act as a converter.\n",
    "The overall context of the user should not be altered. Just provide the final output and nothing else.\n",
    "The ouput should be in format:\n",
    "{\"professional_text\": \"your answer here\"}\n",
    "\"\"\"\n",
    "\n",
    "casual_agent = \"\"\"\n",
    "You are an agent that makes user sentences sound more casual.\n",
    "-----------------------------------\n",
    "#Example1\n",
    "\"input_sentence\":\"who is the pm of nepal?\"\n",
    "\"response\":\"Who's currently running the show as Nepal's Prime Minister?\"\n",
    "\n",
    "#Example2\n",
    "\"input_sentence\":\"why is the sky blue?\"\n",
    "\"response\":\"why does the sky appear bue?\"\n",
    "\n",
    "#Example3\n",
    "\"input_sentence\":\"Why aren't you increasing my salary\"\n",
    "\"response\":\"Why isn't my salary getting a boost?\"\n",
    "\n",
    "#Example4\n",
    "\"input_sentence\":\"@5f6ce9efd4f4417b812267cfecf7dcea  are you free this weekend?\"\n",
    "\"response\":\"@5f6ce9efd4f4417b812267cfecf7dcea, got some free time this weekend?\"\n",
    "\n",
    "#Example5\n",
    "\"input_sentence\":\"@team, why are you guys lagging so much?\"\n",
    "\"response\":\"@team Why's the lag so bad, folks? \"\n",
    "\n",
    "#Example6\n",
    "\"input_sentence\":\"@here, i am leaving early today not feeling well\"\n",
    "\"response\":\"@here feeling under the weather, so I'm heading out early today. Thanks for understanding! \"\n",
    "\n",
    "#Example7\n",
    "\"input_sentence\":\"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "\"response\":\"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "\n",
    "#Example8\n",
    "\"input_sentence\":\"Nepal\"\n",
    "\"response\":\"Nepal\"\n",
    "-------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "casual_instructions = \"\"\"\n",
    "Your job is convert the user's input to make it more casual. Just act as a converter.\n",
    "The overall context of the user should not be altered. Just provide the final output and nothing else.\n",
    "The ouput should be in format:\n",
    "{\"casual_text\": \"your answer here\"}\n",
    "\"\"\"\n",
    "\n",
    "shorten_agent = \"\"\"\n",
    "You are an agent that shortens the users long text preserving the actual intent of the user..\n",
    "--------------------------------------------------\n",
    "Example1. \n",
    "\"input_sentence\": \"I often find myself in a state of mind or say a place mentally where I yearn to return to the sanctuary of my abode, while simultaneously harboring a vehement aversion towards the prospect of engaging in any sort of laborious activity. As I ponder the course of action that would best satisfy my current desires, I cannot help but wonder if there exists a way to reconcile these seemingly disparate impulses.\" \n",
    "\"response\" : \"I often want to go home and avoid doing any work. I wonder if there's a way to balance these desires.\"\n",
    "\n",
    "Example2. \n",
    "\"input_sentence\": \"As I reflect on the past year's worth of effort and dedication, I find myself yearning for a modest increase in my salary. I understand that the decision ultimately lies with the powers that be, but I hope that my contributions and achievements have not gone unnoticed.\" \n",
    "\"response\" : \"I hope my hard work has been noticed and I want a salary increase.\"\n",
    "\n",
    "Example3. \n",
    "\"input_sentence\": \"@5f6ce9efd4f4417b812267cfecf7dcea, as we navigate through the ebb and flow of our busy lives, I find myself pondering upon the precious commodity we often take for granted - time. In the context of our social engagements and personal commitments, I am compelled to inquire about your availability for the upcoming weekend. Are you able to allocate some of this valuable resource to engage in potentially enriching experiences or fulfilling obligations?\" \n",
    "\"response\" : \"@5f6ce9efd4f4417b812267cfecf7dcea  are you free this weekend?\"\n",
    "\n",
    "Example4. \n",
    "\"input_sentence\": \"@team, I am looking forward to our outing this weekend. I hope everyone is as excited as me. It's going to be a lot of fun with all of you. I also wish to encourage all of your participation to make this outing a success\" \n",
    "\"response\" : \"@team, excited for the weekend outing, let's have fun together and make it a success with your participation.\"\n",
    "\n",
    "Example5. \n",
    "\"input_sentence\": \"@here can you all please give me your updates? have all the bugs been fixed? also can someone let me know about the optimization results and how stable is everything at the moment\" \n",
    "\"response\" : \"@here, updates on bugs, optimizations, and system stability, please.\"\n",
    "\n",
    "#Example6\n",
    "\"input_sentence\":\"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "\"response\":\"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "\n",
    "#Example7\n",
    "\"input_sentence\":\"Nepal\"\n",
    "\"response\":\"Nepal\"\n",
    "------------------------------------------------------------\n",
    "    \"\"\"\n",
    "shorten_instruction = \"\"\"\n",
    "Please provide a concise summary of the input sentence while preserving its core meaning.\n",
    "Do not change the tone of the sentence. If it's in active voice, the shortened version should remain active, and the same applies to passive voice.\n",
    "The out should be in the format:\n",
    "{\"short_text\": \"your answer here\"}\n",
    "\"\"\"\n",
    "\n",
    "elaborate_agent = \"\"\"\n",
    "You are an agent that elaborates the user input.\n",
    "Your job is not to answer questions but to make them longer and descriptive.\n",
    "----------------------------------------------------\n",
    "Example 1.\n",
    "input_sentence = \"Who are you?\"\n",
    "response = \"Could you please introduce yourself and provide some information about who you are? I'm interested in getting to know you better, understanding your background, experiences, and the things that define you as a unique individual.\"\n",
    "Example 2.\n",
    "input_sentence = \"I want an early leave today.\"\n",
    "response = \"I wish to convey my sincere hope that you can empathize with and possibly accommodate my humble request. Certain circumstances have converged in such a manner that I find myself desiring to seek a slight modification to my usual departure schedule for today, with the aim of securing an earlier exit from our workplace or engagement.\"\n",
    "Example 3.\n",
    "input_sentence = \"@5f6ce9efd4f4417b812267cfecf7dcea are you free this weekend?\"\n",
    "response = \"@5f6ce9efd4f4417b812267cfecf7dcea, I hope this message finds you well. I wanted to check in and see if you might be available or have any free time this upcoming weekend, as I'm considering planning an event and thought it would be great to have your input, insights, and potentially your participation. Your availability would be greatly appreciated in helping us make the most of the weekend. Thank you for considering this request.\"\n",
    "Example 4.\n",
    "input_sentence = \"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "response = \"@5f6ce9efd4f4417b812267cfecf7dcea\"\n",
    "Example 5.\n",
    "input_sentence =\"John Doe\"\n",
    "response =  \"John Doe\"\n",
    "\n",
    "-----------------------------------------------------    \n",
    "\"\"\"\n",
    "\n",
    "elaborate_instruction = \"\"\"\n",
    "Rewrite the user input to make it 2-3 times longer.\n",
    "Do not change the tone of the input. If it's in active voice, the elaborated version should remain active, and the same applies to passive voice.\n",
    "The out should be in the format:\n",
    "{\"elaborate_text\": \"your answer here\"}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AiPrompts:\n",
    "\n",
    "    grammar_prompt = Prompt(system_prompt=grammar_agent, system_instruction=grammar_instructions, response=\"correct_text\")\n",
    "    professional_prompt = Prompt(system_prompt=professional_agent, system_instruction=professional_instructions, response=\"professional_text\")\n",
    "    casual_prompt = Prompt(system_prompt=casual_agent, system_instruction=casual_instructions, response=\"casual_text\")\n",
    "    shorten_prompt = Prompt(system_prompt=shorten_agent, system_instruction=shorten_instruction, response=\"short_text\")\n",
    "    elaborate_prompt = Prompt(system_prompt=elaborate_agent, system_instruction=elaborate_instruction, response=\"elaborate_text\")\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2da882b-f11e-48a7-88fd-4bc09093ce10",
   "metadata": {},
   "source": [
    "import guidance\n",
    "from guidance import models, system, user, gen, assistant, instruction\n",
    "import regex as re\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "\n",
    "class LlmService:\n",
    "    def __init__(self, device: str = \"auto\", **kwargs):\n",
    "        self.device = device\n",
    "        self.llm = models.LlamaCppChat(model=\"/root/.cache/huggingface/hub/models--TheBloke--phi-2-orange-GGUF/snapshots/bc00cf2118e438f3cdaff101a08c0b41bd7580ef/phi-2-orange.Q8_0.gguf\",n_ctx=4096, n_gpu_layers=-1)\n",
    "\n",
    "    def inference_stream(self, input_text: str = None, clear_cache: bool = True):\n",
    "        if clear_cache:\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        reply_text = \"\"\n",
    "        try:\n",
    "            for output in self.llm.stream() + get_lm_for_ai_assistant(input_text=input_text):\n",
    "                output = str(output).split(\"[/INST]\")[-1]\n",
    "                reply_text = output\n",
    "        except:\n",
    "            return reply_text\n",
    "        return reply_text\n",
    "\n",
    "\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def inference(self, input_text: str = None,\n",
    "                  task_type: TaskType = None) -> str:\n",
    "\n",
    "        print(\"Performing %s via Guidance for input %s\", task_type, input_text)\n",
    "        reply = \"\"\n",
    "        try:\n",
    "            for out in self.llm.stream() + get_lm_check_grammar(input_text=input_text):\n",
    "                reply = str(out)\n",
    "        except:\n",
    "            print(reply)\n",
    "\n",
    "            return self._post_process_response(reply)\n",
    "\n",
    "    def get_lm_for_raw(self, prompt, input_text):\n",
    "        lm = self.llm + prompt.replace(\"{{input_sentence}}\", input_text)\n",
    "        return lm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def _pre_process(self, input_text: str) -> str:\n",
    "        clean_text = re.sub('<.*?>', '', input_text)\n",
    "        return clean_text\n",
    "\n",
    "    def _post_process_response(self, response:str) -> str:\n",
    "        import json\n",
    "        response = response.split(\"[/INST]\")[-1]\n",
    "        print(response)\n",
    "        response = response.strip().replace(\":'\", \":\\\"\").replace(\"'}\", \"\\\"}\").replace(\"{'\", \"{\\\"\").replace(\"':\",\"\\\":\")\n",
    "        print(response)\n",
    "        response = json.loads(response)\n",
    "        return response[\"corrected_text\"]\n",
    "\n",
    "    # def _post_process_generative_response(self, response):\n",
    "\n",
    "\n",
    "\n",
    "@guidance\n",
    "def get_lm_for_ai_assistant(lm, input_text):\n",
    "    with system():\n",
    "        lm = lm + \"You are a helpful ai assistant that answers user query in friendly and polite manner.\"\n",
    "    with user():\n",
    "        lm += input_text\n",
    "    with assistant():\n",
    "        lm += gen(\"response\", max_tokens=200, stop=\"<<< [SYS] >>\")\n",
    "    return lm[\"response\"]\n",
    "\n",
    "@guidance\n",
    "def get_lm_check_grammar(lm, input_text):\n",
    "    with system():\n",
    "        lm = lm + (\"You are a grammar correcting agent. You correct errors in grammar and spellings of the user's input.\"\n",
    "                   \"Just return the corrected sentence and nothing else.\")\n",
    "    with user():\n",
    "        lm  += \"Please correct the grammar for the following sentence. Please respond with {'corrected_text':'your response here' }\" + input_text\n",
    "    with assistant():\n",
    "        lm += gen(\"corrected_text\", stop=[\"SYS\", \"[/INST]\",\"[INST]\"], max_tokens=200)        \n",
    "    return lm[\"corrected_text\"]\n",
    "\n",
    "@guidance\n",
    "def get_lm_professional(lm, input_text):\n",
    "    with system():\n",
    "        lm = lm + (\"You are an agent that  converts user's input to make them sound more professional. Make the user sound very professional.\")\n",
    "    with user():\n",
    "        lm  += \"Please make my sentence more professional. Please respond in  {'professional':'your response here' }\\n\" + input_text\n",
    "    with assistant():\n",
    "        lm += gen(\"professional_response\", stop=[\"SYS\",\"[/INST]\",\"[INST]\"], max_tokens=200)        \n",
    "    return lm[\"professional_response\"]\n",
    "\n",
    "@guidance\n",
    "def get_lm_casual(lm, input_text):\n",
    "    with system():\n",
    "        lm = lm + (\"You are an agent that  converts user's input to make them sound more casual. Make the user sound casual.\")\n",
    "    with user():\n",
    "        lm  += \"Please make my sentence more casual. Please respond in  {'casual':'your response here' }\\n\" + input_text\n",
    "    with assistant():\n",
    "        lm += gen(\"casual_response\", stop=[\"SYS\",\"[/INST]\",\"[INST]\"], max_tokens=200)        \n",
    "    return lm[\"casual_response\"]\n",
    "    \n",
    "@guidance\n",
    "def get_lm(lm, input_text, task_type:TaskType):\n",
    "    prompt = Prompt()\n",
    "    if task_type == TaskType.CASUAL:\n",
    "        prompt = AiPrompts.casual_prompt\n",
    "    elif task_type == TaskType.SHORTEN:\n",
    "        prompt = AiPrompts.shorten_prompt\n",
    "    elif task_type == TaskType.ELABORATE:\n",
    "        prompt = AiPrompts.elaborate_prompt\n",
    "    elif task_type == TaskType.PROFESSIONAL:\n",
    "        prompt = AiPrompts.professional_prompt\n",
    "    elif task_type == TaskType.GRAMMAR_CHECK:\n",
    "        prompt = AiPrompts.grammar_prompt\n",
    "    with system():\n",
    "        lm = lm + prompt.system_prompt + \"\\n\" + prompt.system_instruction\n",
    "    # with instruction():\n",
    "    #     lm += prompt.system_instruction\n",
    "    with user():\n",
    "        lm += input_text\n",
    "    with assistant():\n",
    "        lm += gen(name=prompt.response)\n",
    "    return lm[prompt.response]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b013c5-c73b-40c2-bbde-584cff31a99c",
   "metadata": {},
   "source": [
    "service = LlmService()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5779ec45-9661-47c8-8b6b-544bd246998e",
   "metadata": {},
   "source": [
    "service.inference(\"da msg iz wrng\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e027f0ec-3c32-4d5a-962a-b9c881b5d906",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
